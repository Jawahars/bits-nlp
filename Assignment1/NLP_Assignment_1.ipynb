{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c7033de0-079f-487f-a7d3-56070dfa9014","cell_type":"markdown","source":"## Group No : 77\n\n## Group Member Names:\n1. SHAILESH KUMAR SINGH\n2. JAWAHARLAL RAJAN S\n","metadata":{}},{"id":"b3e85914-ba01-4a81-80f4-09cf7de25230","cell_type":"markdown","source":"# NLP Assignment 1\n\nThis notebook covers the tasks outlined in the problem statement for processing the given dataset. Each step includes explanations, code implementation, and justifications for the output.\n\n### Tasks Overview:\n1. Cleaning: Removing punctuation, numbers, and special characters. Eliminating stop words.\n2. Normalization: Reducing words to their base or root form using stemming or lemmatization.\n3. POS Tagging:\n   - Frequency of POS tags.\n   - Most common POS tags.\n   - Sentences containing specific POS tags.\n4. Visualizations: Representing POS tag frequencies with bar charts and word clouds.\n5. HMM POS Tagging: Applying to the first 4 rows.\n6. POS and NER Tagging Analysis.\n","metadata":{}},{"id":"4b837948-5ca6-4592-aaca-dea5472ef77b","cell_type":"markdown","source":"Import Libraries and Download Resources","metadata":{}},{"id":"4d6184df-41d5-4cc2-9f84-31b1f26cce81","cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nimport spacy\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\n# Download necessary NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"74495bc5-6582-4ee1-8f83-4aa8eb3a6668","cell_type":"markdown","source":"Load and Preview the Dataset\n\nThis cell loads the dataset from the given URL and previews its structure. The script ensures that the dataset has a 'text' column for further processing.","metadata":{}},{"id":"a1cb9b30-8122-426d-927f-f5c7ee338e4e","cell_type":"code","source":"# Importing necessary libraries\nimport pandas as pd\n\n# Load the dataset\nurl = \"https://drive.google.com/uc?export=download&id=1MrOqsO6HajwraBGnvcu9NLoI63c5DvcE\"  # Adjusted link for direct download\ndf = pd.read_csv(url)\n\n# Display the first few rows\nprint(\"Dataset Overview:\")\ndf.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"977cdf00-2bce-4507-b659-5d018b9ac072","cell_type":"markdown","source":"### Data Cleaning\nThis cell cleans the dataset by removing punctuation, numbers, special characters, and stopwords. The cleaned text is stored in a new column.","metadata":{}},{"id":"52c56cd6-5b75-439a-a1b5-73b7abf5d408","cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nfrom nltk.corpus import stopwords\n\n# Preprocess the text column (assuming 'body' is the column with the reviews)\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    # Remove punctuation and numbers\n    text = re.sub(f\"[{string.punctuation}0-9]\", \"\", text)\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    # Convert to lowercase and remove stop words\n    text = ' '.join([word for word in text.lower().split() if word not in stop_words])\n    return text\n\n# Apply the cleaning function\ndf['cleaned_body'] = df['body'].apply(clean_text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d5731131-9d43-48b2-a354-8d5cf5d46f3c","cell_type":"markdown","source":"## Normalization\n\nThis cell normalizes the cleaned text by reducing words to their base form using lemmatization.","metadata":{}},{"id":"763ce29d-2db2-49be-9635-12335c71e8b9","cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3902d8af-12cf-4fd0-b43e-9df1c4a0f31c","cell_type":"code","source":"from nltk import pos_tag\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\n# Helper function to map POS tag to WordNet format\ndef get_pos_tag(word):\n    tag = pos_tag([word])[0][1]\n    if tag.startswith('J'):\n        return 'a'  # adjective\n    elif tag.startswith('V'):\n        return 'v'  # verb\n    elif tag.startswith('N'):\n        return 'n'  # noun\n    elif tag.startswith('R'):\n        return 'r'  # adverb\n    else:\n        return 'n'  # default to noun if unknown\n\n# Lemmatization function\ndef lemmatize_text(text):\n    tokens = word_tokenize(text)\n    lemmatized_text = [\n        lemmatizer.lemmatize(word, get_pos_tag(word)) for word in tokens\n    ]\n    return ' '.join(lemmatized_text)\n\n# Apply lemmatization to the cleaned text\ndf['lemmatized_body'] = df['cleaned_body'].apply(lemmatize_text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0aea5e95-04f8-4818-91ba-10e2b93a49ce","cell_type":"markdown","source":"POS Tagging and Analysis","metadata":{}},{"id":"9e2524ce-b298-4791-91ee-957044fe38d4","cell_type":"code","source":"import spacy\n\n# Load the English NLP model\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef pos_tagging(text):\n    doc = nlp(text)\n    return [(token.text, token.pos_) for token in doc]\n\n# Apply POS tagging\ndf['pos_tags'] = df['lemmatized_body'].apply(pos_tagging)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbcd3478-d5bc-4008-a8e0-4819c658f2cf","cell_type":"markdown","source":"### Extract Sentences with Specific POS Tags\n\nThis cell extracts and displays sentences containing specific POS tags, such as nouns and verbs.","metadata":{}},{"id":"c264667f-0d92-4297-9f03-1228de90d8d1","cell_type":"code","source":"# Function to extract sentences containing a specific POS tag\ndef extract_sentences_with_pos(pos, text_column):\n    result = []\n    for text in text_column:\n        doc = nlp(text)\n        if any(token.pos_ == pos for token in doc):\n            result.append(text)\n    return result\n\n# Extract sentences with nouns and verbs\nnouns_sentences = extract_sentences_with_pos(\"NOUN\", df['normalized_text'])\nverbs_sentences = extract_sentences_with_pos(\"VERB\", df['normalized_text'])\n\n# Display sample sentences\nprint(\"Sentences containing nouns (First 5):\")\nprint(nouns_sentences[:5])\n\nprint(\"Sentences containing verbs (First 5):\")\nprint(verbs_sentences[:5])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e676bf26-0593-4a78-9374-33da462a5478","cell_type":"markdown","source":"### Visualizations\n\nThis cell generates visualizations (bar chart and word cloud) to represent the frequencies of POS tags.","metadata":{}},{"id":"6e199810-5a92-4e5e-91d0-f60edeb3da36","cell_type":"code","source":"# Bar chart for POS tag frequencies\nplt.figure(figsize=(10, 6))\nplt.bar(pos_counts.keys(), pos_counts.values(), color='skyblue')\nplt.title(\"POS Tag Frequencies\")\nplt.xlabel(\"POS Tags\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Word cloud for POS tag frequencies\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(pos_counts)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f5161358-3bb8-418e-9a73-c0000aff34bd","cell_type":"markdown","source":"### HMM POS Tagging on First 4 Rows\n\nThis cell performs HMM POS tagging on the first four rows of the dataset.","metadata":{}},{"id":"3f4a3e18-522c-4001-8954-2cdbc506ca71","cell_type":"code","source":"# Import HMM POS Tagger from NLTK\nfrom nltk.tag import hmm\n\n# Function for HMM POS tagging\ndef hmm_pos_tagging(text):\n    tokens = word_tokenize(text)\n    tagged = nltk.pos_tag(tokens)\n    return tagged\n\n# Apply HMM POS tagging to the first 4 rows\nfirst_four_rows = df['normalized_text'][:4].apply(hmm_pos_tagging)\nprint(\"HMM POS Tagging for the first 4 rows:\")\nprint(first_four_rows)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4b53ea95-906e-4664-a4ca-49513d55777e","cell_type":"markdown","source":"### POS and NER Tagging\n\nThis cell compares POS and NER tags for selected sentences to identify conflicts or complementarities.","metadata":{}},{"id":"8f3293ae-34d5-4a8f-baed-46b04bd665eb","cell_type":"code","source":"# Function for NER tagging\ndef ner_tagging(text):\n    doc = nlp(text)\n    return [(ent.text, ent.label_) for ent in doc.ents]\n\n# Analyze POS and NER tags for sample sentences\nsample_sentences = df['normalized_text'][:5]\npos_ner_analysis = {}\n\nfor sentence in sample_sentences:\n    pos_tags = pos_tagging(sentence)\n    ner_tags = ner_tagging(sentence)\n    pos_ner_analysis[sentence] = {\"POS Tags\": pos_tags, \"NER Tags\": ner_tags}\n\n# Display analysis\nprint(\"POS and NER Tagging Analysis:\")\nfor sent, analysis in pos_ner_analysis.items():\n    print(f\"Sentence: {sent}\")\n    print(f\"POS Tags: {analysis['POS Tags']}\")\n    print(f\"NER Tags: {analysis['NER Tags']}\")\n\n# Identify conflicting/complementary information\nprint(\"Conflicting/Complementary Analysis:\")\nfor sent, analysis in pos_ner_analysis.items():\n    pos_entities = {token for token, tag in analysis['POS Tags'] if tag == 'NOUN'}\n    ner_entities = {entity for entity, label in analysis['NER Tags']}\n    conflicting = pos_entities.difference(ner_entities)\n    complementary = pos_entities.intersection(ner_entities)\n    print(f\"Sentence: {sent}\")\n    print(f\"Conflicting Entities: {conflicting}\")\n    print(f\"Complementary Entities: {complementary}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}